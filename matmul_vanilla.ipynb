{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pycuda.driver as cuda\n",
      "import pycuda.autoinit\n",
      "from pycuda.compiler import SourceModule\n",
      "import numpy\n",
      "import time\n",
      "import os"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wdth = 4096\n",
      "M = numpy.random.randn(wdth,wdth)\n",
      "N = numpy.random.randn(wdth,wdth)\n",
      "P = numpy.empty_like(M)\n",
      "\n",
      "M = M.astype(numpy.float32)\n",
      "N = N.astype(numpy.float32)\n",
      "P = P.astype(numpy.float32)\n",
      "\n",
      "M_gpu = cuda.mem_alloc(M.nbytes)\n",
      "N_gpu = cuda.mem_alloc(N.nbytes)\n",
      "P_gpu = cuda.mem_alloc(P.nbytes)\n",
      "\n",
      "cuda.memcpy_htod(M_gpu, numpy.getbuffer(M))\n",
      "cuda.memcpy_htod(N_gpu, numpy.getbuffer(N))\n",
      "cuda.memcpy_htod(P_gpu, numpy.getbuffer(P))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "code = \"\"\"\n",
      "\n",
      "    #define TILE_WIDTH 32\n",
      "\n",
      "    __global__ void MatrixMulKernel(float *Md, float *Nd, float *Pd, int Width)\n",
      "    {\n",
      "        int Row = blockIdx.y * TILE_WIDTH + threadIdx.y;\n",
      "        int Col = blockIdx.x * TILE_WIDTH + threadIdx.x;\n",
      "\n",
      "        float Pvalue = 0;\n",
      "        for(int k=0; k<Width; ++k)\n",
      "            Pvalue += Md[Row * Width + k] * Nd[k * Width + Col];\n",
      "        \n",
      "        Pd[Row * Width + Col] = Pvalue;\n",
      "    }\n",
      "    \n",
      "    __global__ void MatrixMulKernelSh(float *Md, float *Nd, float *Pd, int Width)\n",
      "    {\n",
      "        __shared__ float Mds[TILE_WIDTH][TILE_WIDTH];\n",
      "        __shared__ float Nds[TILE_WIDTH][TILE_WIDTH];\n",
      "        \n",
      "        int bx = blockIdx.x;\n",
      "        int by = blockIdx.y;\n",
      "        int tx = threadIdx.x;\n",
      "        int ty = threadIdx.y;\n",
      "        \n",
      "        int Row = by * TILE_WIDTH + ty;\n",
      "        int Col = bx * TILE_WIDTH + tx;\n",
      "        \n",
      "        float Pvalue = 0;\n",
      "        for(int m=0; m<Width/TILE_WIDTH; ++m){\n",
      "            Mds[ty][tx] = Md[Row*Width + (m*TILE_WIDTH + tx)];\n",
      "            Nds[ty][tx] = Nd[(m*TILE_WIDTH + ty)*Width + Col];\n",
      "            __syncthreads();\n",
      "            \n",
      "            for(int k=0; k<TILE_WIDTH; ++k)\n",
      "                Pvalue += Mds[ty][k] * Nds[k][tx];\n",
      "            __syncthreads();\n",
      "        }\n",
      "        \n",
      "        Pd[Row*Width + Col] = Pvalue;\n",
      "    }\n",
      "    \n",
      "    \"\"\"\n",
      "\n",
      "mod = SourceModule(code)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "grid = (wdth/32, wdth/32)\n",
      "block = (32, 32, 1)\n",
      "\n",
      "func = mod.get_function(\"MatrixMulKernel\")\n",
      "func.prepare(\"PPPi\")\n",
      "\n",
      "start = time.clock()\n",
      "func.prepared_call(grid, block, M_gpu, N_gpu, P_gpu, wdth)\n",
      "cuda.memcpy_dtoh(P, P_gpu)\n",
      "end = time.clock()\n",
      "\n",
      "print(end - start)\n",
      "print P"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.022378\n",
        "[[-45.15173721   6.92629004  27.12292099 ...,   0.24193028 -28.11282539\n",
        "   35.96567154]\n",
        " [ -2.95599985 -44.62412643 -20.15236855 ...,  21.75033188   0.55976045\n",
        "  -59.77232742]\n",
        " [-18.8644619   29.91902924  -3.08819151 ..., -36.28720474  -2.71362662\n",
        "   21.75301552]\n",
        " ..., \n",
        " [ 66.60072327  -9.98058605   1.76349902 ..., -54.45514679 -40.63799286\n",
        "   40.34282303]\n",
        " [-41.99798584  88.38514709 -22.2514267  ...,  44.91942215 -13.81241798\n",
        "  -39.39190674]\n",
        " [-16.32948112 -30.59397125   6.89537477 ...,  55.02938461  18.12589264\n",
        "   18.46197319]]\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "func = mod.get_function(\"MatrixMulKernelSh\")\n",
      "func.prepare(\"PPPi\")\n",
      "\n",
      "start = time.clock()\n",
      "func.prepared_call(grid, block, M_gpu, N_gpu, P_gpu, wdth)\n",
      "cuda.memcpy_dtoh(P, P_gpu)\n",
      "end = time.clock()\n",
      "\n",
      "print(end - start)\n",
      "print P"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.009472\n",
        "[[-45.15173721   6.92629004  27.12292099 ...,   0.24193028 -28.11282539\n",
        "   35.96567154]\n",
        " [ -2.95599985 -44.62412643 -20.15236855 ...,  21.75033188   0.55976045\n",
        "  -59.77232742]\n",
        " [-18.8644619   29.91902924  -3.08819151 ..., -36.28720474  -2.71362662\n",
        "   21.75301552]\n",
        " ..., \n",
        " [ 66.60072327  -9.98058605   1.76349902 ..., -54.45514679 -40.63799286\n",
        "   40.34282303]\n",
        " [-41.99798584  88.38514709 -22.2514267  ...,  44.91942215 -13.81241798\n",
        "  -39.39190674]\n",
        " [-16.32948112 -30.59397125   6.89537477 ...,  55.02938461  18.12589264\n",
        "   18.46197319]]\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "start = time.clock()\n",
      "P_cpu = numpy.dot(M,N)\n",
      "end = time.clock()\n",
      "print(end - start)\n",
      "print P_cpu"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.572233\n",
        "[[-45.15174484   6.92629385  27.12291336 ...,   0.24192324 -28.11281967\n",
        "   35.96566391]\n",
        " [ -2.95600414 -44.62412262 -20.15236855 ...,  21.75032806   0.55975622\n",
        "  -59.7723465 ]\n",
        " [-18.86447334  29.91903305  -3.08819103 ..., -36.28720474  -2.71362853\n",
        "   21.75301552]\n",
        " ..., \n",
        " [ 66.60071564  -9.98058128   1.76349401 ..., -54.45515823 -40.63798904\n",
        "   40.34283066]\n",
        " [-41.99797821  88.38515472 -22.25142288 ...,  44.91942596 -13.81241417\n",
        "  -39.39189911]\n",
        " [-16.32948112 -30.59397316   6.89538193 ...,  55.02939224  18.12589645\n",
        "   18.46197701]]\n"
       ]
      }
     ],
     "prompt_number": 16
    }
   ],
   "metadata": {}
  }
 ]
}