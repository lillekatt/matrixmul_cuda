{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pycuda.driver as cuda\n",
      "import pycuda.autoinit\n",
      "from pycuda.compiler import SourceModule\n",
      "import numpy\n",
      "import time\n",
      "import os"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wdth = 7680\n",
      "M = numpy.random.randn(wdth,wdth)\n",
      "N = numpy.random.randn(wdth,wdth)\n",
      "P = numpy.empty_like(M)\n",
      "\n",
      "M = M.astype(numpy.float32)\n",
      "N = N.astype(numpy.float32)\n",
      "P = P.astype(numpy.float32)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class MatrixMultiplication:\n",
      "    # need 8 (int+padding) + 3*8 (float pointers) = 32 bytes\n",
      "    mem_size = 8 + 3*numpy.intp(0).nbytes\n",
      "    def __init__(self, Width, M, N, P, ptr):\n",
      "        # copy matrices to GPU and get the pointer the matrices in global memory\n",
      "        self.M_alloc = cuda.to_device(M)\n",
      "        self.N_alloc = cuda.to_device(N)\n",
      "        self.P_alloc = cuda.to_device(P)\n",
      "        # this is used for printing output only, so we only care about the shape and type of P\n",
      "        self.shape, self.dtype = P.shape, P.dtype\n",
      "        # copy values to be used by MatrixMulKernel to global memory\n",
      "        cuda.memcpy_htod(numpy.intp(ptr), numpy.getbuffer(numpy.int32(Width)))\n",
      "        cuda.memcpy_htod(numpy.intp(ptr)+8, numpy.getbuffer(numpy.intp(self.M_alloc)))\n",
      "        cuda.memcpy_htod(numpy.intp(ptr)+8+numpy.intp(0).nbytes, numpy.getbuffer(numpy.intp(self.N_alloc)))\n",
      "        cuda.memcpy_htod(numpy.intp(ptr)+8+2*numpy.intp(0).nbytes, numpy.getbuffer(numpy.intp(self.P_alloc)))\n",
      "    def __repr__(self):\n",
      "        return str(cuda.from_device(self.P_alloc, self.shape, self.dtype))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "start = time.clock()\n",
      "# allocate memory and get pointer to start of block of memory\n",
      "struct_loc = cuda.mem_alloc(MatrixMultiplication.mem_size)\n",
      "# create Python struct\n",
      "multiply = MatrixMultiplication(Width=wdth, M=M, N=N, P=P, ptr=struct_loc)\n",
      "end = time.clock()\n",
      "print(\"Copying to device took: \"+str(end-start))\n",
      "\n",
      "grid = (wdth/32, wdth/32)\n",
      "block = (32, 32, 1)\n",
      "\n",
      "mod = cuda.module_from_file(os.getcwd()+\"/matrixmul.cubin\")\n",
      "func = mod.get_function(\"MatrixMulKernel\")\n",
      "func.prepare(\"P\")\n",
      "\n",
      "start = time.clock()\n",
      "func.prepared_call(grid, block, struct_loc)\n",
      "end = time.clock()\n",
      "print(\"GPU computation time: \"+'{:.9f}'.format(end-start))\n",
      "\n",
      "print(multiply)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Copying to device took: 0.260508\n",
        "GPU computation time: 0.000284000\n",
        "[[ 103.25276947  116.38175201   31.87959671 ...,  129.56930542\n",
        "   125.53045654  128.76177979]\n",
        " [-122.28397369  -68.50110626   65.47225189 ...,  -69.71980286\n",
        "  -166.25315857   31.49713516]\n",
        " [ -11.61681747  107.38838959   69.15325165 ...,   38.9301033   -52.87706757\n",
        "   -86.18589783]\n",
        " ..., \n",
        " [-140.59335327   -5.05160236 -151.88845825 ...,   30.18758583\n",
        "   -53.65579987  -35.55505371]\n",
        " [  57.09960938  -10.70316219   44.73683548 ...,   61.25617599\n",
        "   -69.68358612  -59.59309387]\n",
        " [  35.8163414     2.27256942   -0.86776114 ...,  -46.75442123\n",
        "   -51.66023254  -38.63887405]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "start = time.clock()\n",
      "# allocate memory and get pointer to start of block of memory\n",
      "struct_loc_sh = cuda.mem_alloc(MatrixMultiplication.mem_size)\n",
      "# create Python struct\n",
      "multiply_sh = MatrixMultiplication(Width=wdth, M=M, N=N, P=P, ptr=struct_loc_sh)\n",
      "end = time.clock()\n",
      "print(\"Copying to device took: \"+str(end-start))\n",
      "\n",
      "grid = (wdth/32, wdth/32)\n",
      "block = (32, 32, 1)\n",
      "\n",
      "func = mod.get_function(\"MatrixMulKernelSh\")\n",
      "func.prepare(\"P\")\n",
      "\n",
      "start = time.clock()\n",
      "func.prepared_call(grid, block, struct_loc_sh)\n",
      "end = time.clock()\n",
      "print(\"GPU computation time with shared memory: \"+'{:.9f}'.format(end-start))\n",
      "\n",
      "print(multiply_sh)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Copying to device took: 0.274863\n",
        "GPU computation time with shared memory: 0.000075000\n",
        "[[ 103.25276947  116.38175201   31.87959671 ...,  129.56930542\n",
        "   125.53045654  128.76177979]\n",
        " [-122.28397369  -68.50110626   65.47225189 ...,  -69.71980286\n",
        "  -166.25315857   31.49713516]\n",
        " [ -11.61681747  107.38838959   69.15325165 ...,   38.9301033   -52.87706757\n",
        "   -86.18589783]\n",
        " ..., \n",
        " [-140.59335327   -5.05160236 -151.88845825 ...,   30.18758583\n",
        "   -53.65579987  -35.55505371]\n",
        " [  57.09960938  -10.70316219   44.73683548 ...,   61.25617599\n",
        "   -69.68358612  -59.59309387]\n",
        " [  35.8163414     2.27256942   -0.86776114 ...,  -46.75442123\n",
        "   -51.66023254  -38.63887405]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "start = time.clock()\n",
      "P_cpu = numpy.dot(M,N)\n",
      "end = time.clock()\n",
      "print(\"CPU computation time: \"+str(end-start))\n",
      "\n",
      "print P_cpu"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU computation time: 264.989547\n",
        "[[ 103.25276184  116.3817215    31.8796196  ...,  129.56933594  125.5304718\n",
        "   128.76176453]\n",
        " [-122.28398895  -68.50112915   65.47228241 ...,  -69.7197876  -166.25317383\n",
        "    31.49712753]\n",
        " [ -11.61685181  107.38837433   69.15327454 ...,   38.93013382\n",
        "   -52.87704468  -86.1858902 ]\n",
        " ..., \n",
        " [-140.5933075    -5.05160284 -151.88842773 ...,   30.18755913\n",
        "   -53.65580368  -35.55509186]\n",
        " [  57.099617    -10.70315266   44.73682022 ...,   61.25615311\n",
        "   -69.68357849  -59.59309387]\n",
        " [  35.81635284    2.27254081   -0.86776239 ...,  -46.75442505\n",
        "   -51.66022491  -38.63886642]]\n"
       ]
      }
     ],
     "prompt_number": 6
    }
   ],
   "metadata": {}
  }
 ]
}