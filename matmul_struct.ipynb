{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pycuda.driver as cuda\n",
      "import pycuda.autoinit\n",
      "from pycuda.compiler import SourceModule\n",
      "import numpy\n",
      "import time"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wdth = 2048\n",
      "M = numpy.random.randn(wdth,wdth)\n",
      "N = numpy.random.randn(wdth,wdth)\n",
      "P = numpy.empty_like(M)\n",
      "\n",
      "M = M.astype(numpy.float32)\n",
      "N = N.astype(numpy.float32)\n",
      "P = P.astype(numpy.float32)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "code = (\"\"\"\n",
      "    #define TILE_WIDTH 32\n",
      "\n",
      "    struct MatrixMulOp {\n",
      "        int Width, __padding; // so 64-bit ptrs can be aligned\n",
      "        float *Md, *Nd, *Pd;\n",
      "    };\n",
      "\n",
      "    __global__ void MatrixMulKernel(MatrixMulOp *mat)\n",
      "    {\n",
      "        int Row = blockIdx.y * TILE_WIDTH + threadIdx.y;\n",
      "        int Col = blockIdx.x * TILE_WIDTH + threadIdx.x;\n",
      "\n",
      "        float Pvalue = 0;\n",
      "        for(int k=0; k<mat->Width; ++k)\n",
      "            Pvalue += mat->Md[Row * mat->Width + k] * mat->Nd[k * mat->Width + Col];\n",
      "        \n",
      "        mat->Pd[Row * mat->Width + Col] = Pvalue;\n",
      "    }\n",
      "    \n",
      "    __global__ void MatrixMulKernelSh(MatrixMulOp *mat)\n",
      "    {\n",
      "        __shared__ float Mds[TILE_WIDTH][TILE_WIDTH];\n",
      "        __shared__ float Nds[TILE_WIDTH][TILE_WIDTH];\n",
      "        \n",
      "        int bx = blockIdx.x;\n",
      "        int by = blockIdx.y;\n",
      "        int tx = threadIdx.x;\n",
      "        int ty = threadIdx.y;\n",
      "        \n",
      "        int Row = by * TILE_WIDTH + ty;\n",
      "        int Col = bx * TILE_WIDTH + tx;\n",
      "        \n",
      "        float Pvalue = 0;\n",
      "        for(int m=0; m<mat->Width/TILE_WIDTH; ++m){\n",
      "            Mds[ty][tx] = mat->Md[Row*mat->Width + (m*TILE_WIDTH + tx)];\n",
      "            Nds[ty][tx] = mat->Nd[(m*TILE_WIDTH + ty)*mat->Width + Col];\n",
      "            __syncthreads();\n",
      "            \n",
      "            for(int k=0; k<TILE_WIDTH; ++k)\n",
      "                Pvalue += Mds[ty][k] * Nds[k][tx];\n",
      "            __syncthreads();\n",
      "        }\n",
      "        \n",
      "        mat->Pd[Row*mat->Width + Col] = Pvalue;\n",
      "    }\n",
      "    \"\"\")\n",
      "\n",
      "mod = SourceModule(source=code,keep=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class MatrixMultiplication:\n",
      "    # need 8 (int+padding) + 3*8 (float pointers) = 32 bytes\n",
      "    mem_size = 8 + 3*numpy.intp(0).nbytes\n",
      "    def __init__(self, Width, M, N, P, ptr):\n",
      "        # copy matrices to GPU and get the pointer the matrices in global memory\n",
      "        self.M_alloc = cuda.to_device(M)\n",
      "        self.N_alloc = cuda.to_device(N)\n",
      "        self.P_alloc = cuda.to_device(P)\n",
      "        # this is used for printing output only, so we only care about the shape and type of P\n",
      "        self.shape, self.dtype = P.shape, P.dtype\n",
      "        # copy values to be used by MatrixMulKernel to global memory\n",
      "        cuda.memcpy_htod(numpy.intp(ptr), numpy.getbuffer(numpy.int32(Width)))\n",
      "        cuda.memcpy_htod(numpy.intp(ptr)+8, numpy.getbuffer(numpy.intp(self.M_alloc)))\n",
      "        cuda.memcpy_htod(numpy.intp(ptr)+8+numpy.intp(0).nbytes, numpy.getbuffer(numpy.intp(self.N_alloc)))\n",
      "        cuda.memcpy_htod(numpy.intp(ptr)+8+2*numpy.intp(0).nbytes, numpy.getbuffer(numpy.intp(self.P_alloc)))\n",
      "    def __repr__(self):\n",
      "        return str(cuda.from_device(self.P_alloc, self.shape, self.dtype))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "start = time.clock()\n",
      "# allocate memory and get pointer to start of block of memory\n",
      "struct_loc = cuda.mem_alloc(MatrixMultiplication.mem_size)\n",
      "# create Python struct\n",
      "multiply = MatrixMultiplication(Width=wdth, M=M, N=N, P=P, ptr=struct_loc)\n",
      "end = time.clock()\n",
      "print(\"Copying to device took: \"+str(end-start))\n",
      "\n",
      "grid = (wdth/32, wdth/32)\n",
      "block = (32, 32, 1)\n",
      "\n",
      "func = mod.get_function(\"MatrixMulKernel\")\n",
      "func.prepare(\"P\")\n",
      "\n",
      "start = time.clock()\n",
      "func.prepared_call(grid, block, struct_loc)\n",
      "end = time.clock()\n",
      "print(\"GPU computation time: \"+'{:.9f}'.format(end-start))\n",
      "\n",
      "print(multiply)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Copying to device took: 0.017849\n",
        "GPU computation time: 0.000072000\n",
        "[[  48.87587738   47.08267593  -32.34881973 ...,   43.7492981   -26.98918533\n",
        "   -23.57923126]\n",
        " [  -8.37238979  -52.25040436   22.37752724 ...,   19.18007469\n",
        "   -22.65793037  -26.23800278]\n",
        " [ -76.94405365   40.88328552  145.25410461 ...,  -30.85367203   28.2302742\n",
        "    -9.71386433]\n",
        " ..., \n",
        " [ -66.32135773  -33.25265503  -83.72055817 ...,   -4.61787653\n",
        "   -23.99094582   -2.42314053]\n",
        " [ -37.86149216    8.60675526  -48.66294479 ...,   12.86450005\n",
        "   -69.86920929  -17.2189827 ]\n",
        " [ -25.06424332  -16.51171684  -26.95980263 ...,   -5.8348999    79.87966156\n",
        "    10.63283348]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "start = time.clock()\n",
      "# allocate memory and get pointer to start of block of memory\n",
      "struct_loc_sh = cuda.mem_alloc(MatrixMultiplication.mem_size)\n",
      "# create Python struct\n",
      "multiply_sh = MatrixMultiplication(Width=wdth, M=M, N=N, P=P, ptr=struct_loc_sh)\n",
      "end = time.clock()\n",
      "print(\"Copying to device took: \"+str(end-start))\n",
      "\n",
      "grid = (wdth/32, wdth/32)\n",
      "block = (32, 32, 1)\n",
      "\n",
      "func = mod.get_function(\"MatrixMulKernelSh\")\n",
      "func.prepare(\"P\")\n",
      "\n",
      "start = time.clock()\n",
      "func.prepared_call(grid, block, struct_loc_sh)\n",
      "end = time.clock()\n",
      "print(\"GPU computation time with shared memory: \"+'{:.9f}'.format(end-start))\n",
      "\n",
      "print(multiply_sh)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Copying to device took: 0.020588\n",
        "GPU computation time with shared memory: 0.000082000\n",
        "[[  48.87587738   47.08267593  -32.34881973 ...,   43.7492981   -26.98918533\n",
        "   -23.57923126]\n",
        " [  -8.37238979  -52.25040436   22.37752724 ...,   19.18007469\n",
        "   -22.65793037  -26.23800278]\n",
        " [ -76.94405365   40.88328552  145.25410461 ...,  -30.85367203   28.2302742\n",
        "    -9.71386433]\n",
        " ..., \n",
        " [ -66.32135773  -33.25265503  -83.72055817 ...,   -4.61787653\n",
        "   -23.99094582   -2.42314053]\n",
        " [ -37.86149216    8.60675526  -48.66294479 ...,   12.86450005\n",
        "   -69.86920929  -17.2189827 ]\n",
        " [ -25.06424332  -16.51171684  -26.95980263 ...,   -5.8348999    79.87966156\n",
        "    10.63283348]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "start = time.clock()\n",
      "P_cpu = numpy.dot(M,N)\n",
      "end = time.clock()\n",
      "print(\"CPU computation time: \"+str(end-start))\n",
      "\n",
      "print P_cpu"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU computation time: 6.004498\n",
        "[[  48.87587738   47.08267593  -32.3488121  ...,   43.74930191  -26.9891777\n",
        "   -23.5792408 ]\n",
        " [  -8.37238884  -52.25040817   22.37751007 ...,   19.18007088  -22.6579361\n",
        "   -26.23801422]\n",
        " [ -76.94406891   40.88329315  145.2540741  ...,  -30.85367584\n",
        "    28.23027039   -9.71384335]\n",
        " ..., \n",
        " [ -66.32138062  -33.2526474   -83.72055054 ...,   -4.61786938  -23.990942\n",
        "    -2.42314434]\n",
        " [ -37.86148834    8.60675812  -48.66294861 ...,   12.86448669\n",
        "   -69.86922455  -17.21899414]\n",
        " [ -25.06422424  -16.51170731  -26.95981407 ...,   -5.83488989\n",
        "    79.87967682   10.6328373 ]]\n"
       ]
      }
     ],
     "prompt_number": 14
    }
   ],
   "metadata": {}
  }
 ]
}